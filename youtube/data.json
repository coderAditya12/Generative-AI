[
  {
    "videoId": "Fv0leN8TmR8",
    "transcript": "We ain't survivin' this f***ing war.We are dead men walking.I'm gonna keep fighting,and if you can't, then I'm just\ngonna fight for both of us.You wouldn't be the first\nto throw their life away in a war.But you would be the first...to save the world doing it.So how about it, you lot?One last go?I'll take that as a yes?A reckoning is coming.Even if I have to drag\nyour broken f***ing carcassesover the finish line,we are going all the way.No matter the cost.Till the job's f***ing done."
  },
  {
    "videoId": "4ejbsDJRfdo",
    "transcript": "Did you know that crocodiles canliterally slow down their heart rate totwo beats per minute and just sit theretotally still for up to an hour, waitingfor the perfect moment to strike? Twobeats per minute, just vibing. Whileeverything around them is screaming,rushing, panicking, overreacting, andflailing around like it's the end of theworld. That prehistoric coldbloodedmurder lizard is just chilling, patient,present, focused, calm. Now, imagine ifyou could do that. Not the murder part.Don't get weird on me. But the calm. Thekind of calm that makes peopleuncomfortable. The kind that doesn'tflinch when everything else is breakingdown. The kind of calm that makes peoplego, \"Why the hell are you not freakingout right now?\" And you just look atthem like, \"Because I trained for this.\"See, we live in a world where everyone'splaying emotional whack-a-ole with theirown anxiety. Stress pops up. Scroll TikTok. Sad. Snack time. Insecure. Buysomething. Edit your selfie. Pretendyou're fine. But the real flex is notreacting. It's watching chaos knock onyour front door and being like, \"Nothanks. I'm not home today.\" That'spower. That's peace. That's the kind ofpresence that doesn't need to proveanything because it is the proof. Butlet's be honest, calm isn't sexy. Dramais. Chaos is. Breaking down in your carwhile scream crying to Phoebe Brides issomehow more relatable than taking adeep breath and saying, \"This too shallpass.\" But what if being unbothered wasyour rebellion? What if your innerstillness was your middle finger to aworld addicted to panic? You ever noticehow the loudest person in the room isusually the most scared and the quietestone probably watching, listening,calculating, already three steps ahead?Because calm isn't weakness. It'sdiscipline. It's emotional jiu-jitsu.It's the art of not letting stupid SATrent space in your head. You don't needto control the storm. You just need tostop letting it control you. But I getit. It's hard. You've been trained toreact. You've been programmed to needthe noise. You open your phone like it'sa defibrillator for your nervous system.You can't even take a dump withoutwatching three conspiracy videos, twocat clips, and a guy in a shed yellingabout real estate. Silence feels likedeath. Stillness feels like failure. Butwhat if it's actually the cure? Here'sthe thing. No one tells you. Yournervous system has no idea how rich youare, how hot you are, how many followersyou have, or how many problems you'repretending not to have. It only knowsone thing. Am I safe right now? Andevery time you go chasing drama,validation, or chaos, it hears no. So,it tightens up, speeds up, freaks outuntil your body becomes a battlefield ofstress and confusion. That's why you'reso tired. That's why your soul feelslike it's running on 2%. That's why evengood days feel like a break betweenbreakdowns. You're not lazy. You're notweak. You're just fried, frazzled,pulled in 20 directions, and somehowstill stuck. You ever felt that? Likeyou're working, surviving, posting,socializing, and still feel like you'renowhere. That's because noise doesn'tmove you forward. It just keeps youspinning. But calm, real, earned,crocodile level calm, that's your exit.That's thehack. Because when you're calm, you stopchasing things that don't matter. Youstop trying to impress people you don'teven like. You stop negotiating yourpeace for cheap dopamine hits that leaveyou more numb than alive. You startshowing up with clarity, with power,with this quiet confidence that makespeople say, \"I don't know what they'vegot, but damn, I want it.\" You know why?Because calm is rare now. And anythingrare is valuable. You ever met someoneso composed it almost pissed you off?Like genuinely. You're in a group chatmeltdown. Everybody's losing their mindsover a typo or some petty drama. Andthis one person is just sipping tea, notresponding, not taking sides, notemotionally invested in the circus, justthere like a mountain, calm, watching,breathing, and you're low-key furiouslike, \"Why are you not freaking out withthe rest of us?\" and they look at youwith this peaceful, unbothered face likethey've already made peace with everyoutcome before it even started. Thatkind of energy is magnetic andterrifying. Because deep down, we allknow we don't have it, at least not yet.Most people are walking around like openwounds with Wi-Fi. Constantly reacting,constantly seekingvalidation, constantly in a silentpanic, looking for the next notificationto give them a crumb of meaning. But thecalm ones, the ones who don't argue,don't gossip, don'toverexlain, don't chase, they feel likealiens or monks or serial killers. It'shard to tell. And it's because we're notused to seeing stillness as strength. Wethink silence means weakness. That notengaging means apathy. But no. Sometimessilence is a strategy. Sometimes peaceis power. And the truth is that kind ofcalm isn't born. It's built. Theyweren't born like that. They chose it.They trained for it. You think theynever had anxiety? You think they neverwanted to clap back or explode or provetheir point? Nah, they just practicedrestraint. They learned the lost art ofshutting the hell up and observing. Theyunderstood that energy is currency. Andevery time you react to nonsense, you'respending yours on trash. That level ofdiscipline doesn't come from books orYouTube clips with alpha energy in thetitle. It comes from reps. Dailyemotional reps.You start small, like that text fromyour ex. The one that makes your stomachdrop and your heart race. Don't respondright away. Just wait. Breathe. Reclaimyour power in that space. Because everytime you pause instead of react, you'rebuilding the muscle. Every time you leta passive aggressive comment slidewithout spiraling into an imaginarycourtroom in your head, you're lifting.Every time you sit with a feelinginstead of running from it, you'readding another brick to your fortress ofchill. It's not glamorous. No one clapsfor you. You don't get a medal for notlosing your at work when yourmanager says something condescending,but you do get stronger. You start tonotice you don't flinch as much. Youdon't overthink as long. You don't getsucked into chaos as easily. You startchoosing peace, not because you're soft,but because you're done paying emotionalrent on places you've already moved outof. And people notice, trust me, theyfeel it before they see it. There's thisquiet power that walks in the roombefore you say a word. It's the vibe ofsomeone who doesn't need to prove a damnthing, who doesn't collapse when they'remisunderstood, who doesn't chase closureor clapbacks or approval. You become theperson who doesn't just have presence,but is presence. Rooted, steady,unshakable. And yeah, it's going toweird people out. Calm confuses thechaotic. It makes insecure people itchy.They'll poke at you, try to stir you,try to figure out what your deal isbecause your peace is louder than theirnoise. And that, my friend, isdeliciously disruptive. It'srevolutionary.In a world that monetizes your fear,rewards your rage, and thrives on yourrestlessness, being calm is a straightuprebellion. It's saying, \"I see yourpanic, and I opt out.\" That's next levelstrength. And it's rare, which makes itpriceless. Because when you meet someonewho's genuinely calm, you're not justseeing someone who's relaxed. You'reseeing someone who's done the work,who's dug through their trauma, who satwith their discomfort, who's walkedthrough their emotional earthquakes andcame out the other side, not untouched,but anchored. They're not immune topain. They just don't let pain drive thecar anymore. They've taken the wheelback and they're cruising, steady,focused, untouchable in the best way. Soif you're building that, if you'relearning to pause, to breathe, to nottake the bait, to hold your powerquietly, keep going. You're doing thehardest thing. You're rewiring yourself.And yeah, it's uncomfortable. There willbe days where you feel like exploding,where silence feels like swallowingglass, where every part of you wants toscream, \"Why am I doing this?\"But then one day someone tries to dragyou into chaos and you just smile. Not asarcastic smile, a peaceful one becauseyou know you've seen that movie. Youknow how it ends. And you've alreadywalked out of that theater. You'rewatching life from a different seat now.You've upgraded. You've evolved. Andyour peace, your composure, it's notpassive. It's active. It's alive. It'spowerful. It's yours. And you earnedit. One uncomfortable breath at a time."
  },
  {
    "videoId": "4ulWHZlBe8Q",
    "transcript": "Now before we get started with thisvideo, I have two very big announcementsto make. The first one being that we arelaunching we make devs scholarships.I'll keep it short. If you want toattend global events like conferences inAmerica, in Europe, these can be quiteexpensive but also very rewarding. Youget a lot of job opportunities. Youbuild your skills. You network. Youexpand your horizons. But let's behonest, very expensive, right? So viaVmake dev scholarships, we are going tocover your flights. We will cover yourhotels for free, flights for free,hotels for free, visa as well, transportas well, conference ticket as well,everything you need. And this issomething you know we wanted to do for awhile. We did it for CubeCon Detroit andnow we are starting it again. So thisapplication uh is now open for CubeConAmsterdam. So if you want to attendCubeCon Amsterdam for free, make sureyou apply. It's uh reviewed on rollingbasis. So first come first- serve basis.We review it. So make sure you apply andall the information can be found on thewebsite that you see on the screen andthe links will be in the descriptionbelow. So you can apply using this link.You can share it on your socials. Youcan check out the previous winners FAQsand you can also join our newsletter ifyou want to stay uptoate about such uhinitiatives and never miss anopportunity. There's also the discordserver you can join and the telegramchannel that you can join. So yes,anyone can apply. It doesn't matter ifyou're a student, you're a beginner, youare just getting started or you're anexperienced professional, you're an opensource maintainer. it does not matter.Make sure you apply early and we arelooking forward to seeing yourapplications and sending a lot morepeople to global conferencesASAP. Announcement number two is quiteexciting. We are doing our biggesthackathon yet and the earlyregistrations are now open. So we aredoing a hackathon in collaboration withCerebras, Meta, previously known asFacebook and Docker, some of the biggestcompanies in the AI space right now. Andthe cash prizes we're going to revealvery soon. It's going to be in thethousands. It's going to be our biggestcash prize yet. But more importantly,the winners will be getting an interviewopportunity at Ceras. You'll be gettinga coffee chat with Meta Engineers. Andthere are some really exciting prizesthat are yet to be announced. This isour biggest hackathon yet. I highlyrecommend forming a team and startingthe early registration today because umyou know uh we get thousands of peopleapply. So make sure you get in your spotASAP. Now, if you don't know whatCerebras is, make sure you watch thisvideo. We're going to cover it in detailand you can sign up using the link inthe description below because you willget 1.5 1.2 million daily tokens freeand no credit card required. This islike really high quality AI models foryour development needs that you will begetting for free. Now, you'll be likekunal I don't know what this is. I don'tknow what inferencing is. I don't knowhow to implement AI in my projects. Idon't know what cerebras is. That iswhat this course is this this wholevideo is about. Okay. So, sign up usingthe link in the description below toCerebras. Make sure you fill out thishackathon early registration form, thescholarship form if you're interested ingoing to Amsterdam for CubeCon. Wow, alot of things happening. I'm so excited.And um if you want to learn more aboutCeras AI inferencing, Gen AI in general,how to get started, watch this videotutorial. It's completely hands-on, soyou will follow along. And withoutfurther ado, let's get started.By 2026, over 80% of the companies willbe using generative AI according toGartner. And in this video, we're goingto talk about generative AI for everyoneand how to get started easily and moreimportantly for free. Starting from thevery basics of various terms that peoplethrow around. By the end of this demo,you'll be setting up a demo of theworld's fastest free AI coding assistantin literally a few minutes that canwrite 4,000 lines of JavaScript in just4 seconds. And you don't need a creditcard to set this up. Now, you're goingto be like, Kunal, AI platforms are veryexpensive. We already know about OpenAI,Gemini, Chat, GPT, and whatnot, but wehave to pay for it. But what if I toldyou that you can get your hands on theworld's fastest AI inference platformfor free. It's called Cerebras and it isthe future of AI. Literally, it'srivaling giants like Nvidia and you cansign up using the link in thedescription below to get 2 milliontokens of the latest Quen 3 coder 480Bmodel for free. I know I've thrown a lotof terms at you. Tokens. Kunal, what isinferencing? Kunal, what is Quen 3?Kunal, what is Cerebras? You said it wasa GNAI beginner course and now you'rethrowing buzzwords at us. So withoutfurther ado, let's get started. Going tobe a lot of fun and it's going to be alot of hands-on and intuitive stuffwhich I'm really excited to showcase. Soyeah, check out the links in thedescription to sign up in just a minute.And uh let's get started. Because thistutorial is called generative AI foreveryone, I assume that a lot of peoplewho are watching this are new to AI. SoI'm going to take a few minutes toexplain to you the basic terminologiesof this ecosystem.What is artificial intelligence? Don'tworry, I'm not going to bore you withthe official definition. You can findthat online if you're curious. Buteveryone knows what AI is. It's like amachine or a program if you want to callit that mimics human behavior. A goodexample is like Jarvis from Iron Man,Robocop and uh you know Terminator, yourSiri, Google Assistant, Chat GPT,whatever. It's trying to mimic the humanbehavior. Okay, that's fine. Easy. Now,what is machine learning? Machinelearning as the name suggests itself isthe process via which the AI becomessmart. But what does that mean? AI isgetting smart via machine learning. Asthe name suggests, your machine islearning. How do me and you get smart?We read. We watch tutorials like this.We read books. We read tutorials. Weread documentation. We gather all thedata and we learn. And that's how webecome smart. That is exactly how AIbecomes smart as well. We have to giveit data. It studies that data and itbecomes smart. Let's take it into uhtake a look at this into a little bitmore detail but in very simple terms.Let's take a look at this real worldexample.We have uh the price of the house in myneighborhood and square foot. So let'ssay the price of the house depends onhow large the house is. Obviously thereare other factors that determine theprice of the house in your neighborhoodas as well. how many rooms it has, whatis the floor, how close it is to therailway station, how close it is to thepark, the basic amenities and otherthings. For the sake of the example, wewill keep it simple. Let's just say theprice depends only on how large thehouse is, meaning how much is the squarefoot area. Let's say for a 400 ft house,this is let's say the real worldexample. So you can see that for 400Thouse, one of the houses in theneighborhood that was 400 ft\u00b2 sold for\u00a3750,000.The other one that was 400 ft\u00b2 sold for\u00a3800,000. That is quite a real worlddata. Similarly,an apartment 800 ft\u00b2 is going to costlet's say 1.4 million or 1.5 million.Now what happens is if I want to createan artificial intelligence program whereI just give it the square foot in thearea and I want it to tell me how muchshould I be paying. I will give mymachine learning algorithm this raw datathat it has not seen before and it willcome up with a generalized answer. Sosomething like this a generalized answerlike this. This is what this is just aline y is equal to mx + c equation of aline very simple you don't have to gointo too much detail it's more aboutintuition so as you can see I have ageneralized answer now and whenever anew data point comes let's say a newdata point is coming and I'm asking ithow much for a 700 or 600 ft house it'sgoing to put it on this line and give methe answer so a generalized answerOkay, obviously it's not going to be thesame as the actual price of the housesthat have been sold for \u00a3600 or\u00a3700,000.It's going to be somewhat different. Sothere's going to be somewhat of anerror. That's basically how accurateyour machine learning model is. Youknow, people say my model is 98%accurate, 99% accurate. That's what itmeans. I won't bore you with thedetails, but this is what it looks like.You give it some sort of a training datain order to make your AI smart. This iswhat machine learning does. You give itsome training data. It will pass itthrough an algorithm and it will createa machine learning model. This can belike a mathematical equation and youpass the new data into this equation. Itwill give you the answer. Very simple.What sort of algorithm to use depends onwhat's what type of data you have. Youcan use logistic regression, linearregression, SVM, knive base or whatever.Now that's a different topic. That'slike very core of machine learning.We're not worried about that. My basicgoal was to make you understand what AIis and what ML is. So when we talk aboutmachine learning, it's a subset of AI.So this is machine learning.Okay, this is ML. It's a part of AI.When you replace this algorithm withwith an artificial neural network, whichis like scientists, you know, our brainshave neurons. They're like, \"Hey, we canmimic this neuron behavior in our brainsin a in code. We can mimic it sort oflike in mathematics.\" So they createdhow our brains work, right? They createda fake sort of like scenario that isknown as deep learning. So you can thinkof deep learning as a part of machinelearning.Okay? So this is the whole landscape.Now what is generative AI? Well,generative AI is AI that can createthings for you. It can be like text, canbe like images or code based on what youask it to do. So for example, chat GPTwriting an essay for you. Darly makingart for you from a description. AIcoding platforms turning a fewinstructions into working code. So it'sspreading across almost every industry.Healthcare, finance, entertainment,customer service, marketing, you nameit. Even Google said that around 25 or20 to 25% of its code is being writtenby AI and people are also creating AIavatars for social media content. Sothere are a lot of uh use cases in theindustry that are happening right now.That's in simple terms what uhgenerative AI is. Now that you knowabout AI, what training means, what GenAI means, let's take a look at some ofthe other terms that you will comeacross. Starting with large languagemodels. Then we'll learn about tokens.You may have also heard about AIinferencing. So what does inferencingmean? We'll take a look at that now.Okay. Next I want to talk to you aboutlarge language models or LLMs. In theprevious simple example, we saw a modelthat predicts the house pricing. Well,large language model. Imagine you'regiving someone billions of books andwebsites and articles to read. Afterreading all of that, they start noticingsome patterns in how the words areformed and how ideas are connectedtogether. For example, if you say peanutbutter and you know that the next wordis going to be probably jelly becauseyou have seen this pattern so many timesin Hindi, you say aluka, the next wordwill be para or para, whatever you wantto call it. So aluka, para, this isexactly what an LLM does. It doesn'tjust think like humans but instead itpredicts the next word the next wordafter that the next word after thatbased on everything it has learned fromhuge amount of text. Now the word largein large language model or LLM comesfrom the size of these models. The lastexample we saw had just one parametersize of the house the square foot of thehouse based on which I will get myanswer. LLMs have billions or eventrillions of parameters which are liketiny adjustable dials the model uses tomake better predictions. The bigger themodel, the more patterns it can captureand the smarter it feels. For example,when you ask chart GP to write code, itcan recall the pattern of how code hasbeen usually written. And when you askit to summarize a book, it will predicta good condensed version based on whatit already knows about summaries. If youwant more information about how LLMswork internally, how they store factsand data, I recommend checking out thechannel 3 Blue One Brown. This is notsponsored by them, by the way. I justreally like that channel. Highlyrecommend checking it out. Okay, let'slearn about another term called tokens.What is a token? A token is a smallpiece of text that AI models read orgenerate. So, instead of working withthe whole sentence or even whole words,models break down text into tokens. Atoken can be as short as a single letteror as long as a whole word depending onthe language and how the model istrained. So for example, the worddeveloper might be split into twotokens, devil and oper. While shortwords like cat or dog would usually bejust one token. And when you interactwith a large language model, everythingthat you're typing is turned intotokens. And the model generates itsanswers one token at a time predictingwhat should come next. So when you writein chart GPT you see chity gives youanswer like uh it's like typing reallyfast. You see it like this you knowthat's what happens. So when you seeterms like um why this is important isbecause you will come across terms like2,000 tokens per second. Someone will belike we are this much faster. We aredoing 2,000 tokens per second. What doesit mean? What does it mean when we saymodels can work with, you know, thespeed of 2,000 tokens per second? Itmeans that the model machine learninggeni model can process or generate about2,000 of these text chunks every second.So in simple terms, you know, thesetokens are just building blocks of howAI understands and produces thelanguage. So now that you know what LLMsare, what tokens are, what generative AIis, the next question is simple. How doyou actually use generative AI? Theanswer is AI inferencing. Very simpleterms, what it means is how you'remaking AI useful. So for example, youhave a chat GPT like platform and you'rewriting in some text. Hey, give me asummary of this paragraph and it'sgiving you an answer. That's AIinferencing. So you're actually callingthe model and getting some answer. Howdo you do it? Let's say there aremachine learning models, these big AImodels. Now in order to host thesemodels it's not easy. You're like kunalif I want to use generative AI I don'twant to deploy my own infrastructure. Iwant someone else to do it and I justwant to let's say call the API. So Iwill give a request to the server andthe server will give me answer. Sothat's way number one. There arecompanies like Cerebras, like OpenAI,Google Gemini. So they are like we willhost these models for you on our ownhardware and you just send us a requestand we will give you the answer. Usuallythe payment plan works like you can domonthly subscription. You know welearned about tokens. So you can pay perthousand tokens or things like that. Sothat's like the easiest way to getstarted. Cerebras is like the fastestway to get started and also for free.you get a million tokens and if you usethe link in the description below, youwill get uh 200,000 tokens more. So,make sure you check it out. So, that'sway number one. I'll tell you a bit moreabout Cerebras shortly. But the secondoption is to self-host. It means thatyou can download an open source modellike Llama, Mistl, Quen or whatever, andyou can run it on your own machine oryour own cloud infrastructure. So thisis going to give you more control, moreprivacy and sometimes lower costs atscale. But it also requires moretechnical setup and more hardware. Nowlet's talk a bit more about how theseLLMs become so smart. I told you before,imagine you're giving billions ofwebsites to the large language model andnow you need to train that model usingthat data which is like billions andbillions of website so much data. Sowhen you're training a model on so muchdata, you need hardware. This is whyGPUs have become quite popular now.Kunal, what is a GPU? Um, it's known asa graphics processing unit. They wereoriginally built for video games,rendering 3D graphics really, reallyfast. But then they realized that thesame thing that makes them so good atgraphics also makes them really reallygood for AI training or training thesebig big models. So why why is it whydoes that make sense? Why do people useGPUs for AI training? Because GPUs cando thousands of calculations at the sametime. And when you're training a largeAI model like LLMs, it requires you tomultiply massive amounts of numbersagain and again and again and again andagain. CPUs do this really slowly. GPUsare optimized exactly for this. And thisis why companies like Nvidia are nowpowering, you know, most of the world'sAI companies or whatnot. But there's acatch. GPUs weren't originally designedjust for AI. So even though they arevery powerful, they can hit limits withthings like memory bandwidth andefficiency when you're training verylarge models. Because generative AImodels create text one token at a time.It's kind of like writing. You you writethe one word, you can't write the nextword until the last one is done, right?So the biggest slowdown is moving datain and out of memory for every singlestep. GPUs often have to shuffle databetween multiple cards or across slowermemory which is eating up a lot of time.Now this is where Cerebras comes in.Instead of using a lot of GPUs wired orattached together, what they did wasthey built something radicallydifferent. They built the world'slargest computer chip. It's like thesize of a dinner plate that's designedfrom scratch for artificialintelligence. Because everything is onthis one giant chip, it's going to avoidmany of the bottlenecks that GPUs face.And that means much much faster trainingand inference speeds because it fixesthe main thing that makes big AI modelsslow and expensive, memory bottlenecks.Their wafer scale engine WSE3 has nearlya million cores and 44 GB of onchipmemory. The result, 20 pabytes persecond of bandwidth, which is over 7,000times faster than Nvidia's H100 GPU.That means you're not waiting around fordata to move. It's just pure speed, andwe will see it in action in this demo.And the performance is wild as well.Cerebras ran 120 billion parameter modelat 3,000 tokens per second which is wayfaster than typical GPU setups.Alibaba's Quen 3 coder 480B instructmodel is also now available on Cerebraswhich we will be demoing in this uhtutorial and it's the world's mostpopular open coding model and it's a2,000 tokens per second. So that turnsmultisecond delays into near instantanswers. And here's the best part. Youdon't need to buy this monster chip byCerebras. They offer a cloud platformwhich can uh run open source models ontheir hardware and no credit card isneeded. So you can get started for free.Getting started is literally going totake you 5 seconds. Click on the link inthe description below so you can getfree 200,000 tokens. Then click on getAPI key and you can sign up using youremail or you can do single sign on usingGoogle or GitHub. I'm going to click onGoogle and then I'm going to select myGoogle account and I will be in theCerebras dashboard. So here in thedashboard you can see the various modelsthat are available to you. If you needaccess to Quen 3 480B coder which islike a top tier coder for uh coding uhcopilot so you can get that for free ifyou use to the link in my description tosign up. Here on your dashboard you cancheck out your API keys. So let's sayyou have a website in which you want tointegrate AI functionality. So you canjust use this API key and you can makedirect calls to Cerebras your platformover here and it's going to give you ananswer. So you can create chat bots, youcan do a bunch of stuff. I'll show you alittle bit how to use this API. You'llsee your uh limits over here as well.The kind of models that are available toyou and the limits and uh you can alsocheck out uh settings. There's variousdocumentationsand a bunch of other stuff. They alsohave a live playground which uh you canuse. So you can essentially try theirmodels on the on their website. So youcan say implement a doubly link list.That took like half a second literally.So you can see how fast that was. Thisis the open-source model byOpenAI but you can change it and useLama and use whatever you like. So, it'squite quite fast. They also have a voicemode. That's essentially about it. Butlet's take a look at uh some more funstuff that you can do with it. Also, whyI recommend signing up is because ontheir free tier, you get around 1million tokens every day for free. Thatis about 750,000words. So, unless you are writing novelsevery day, you're going to be okay. Andeven if you go over the limit, the paidrates are quite quite cheap andaffordable. It's also super developerfriendly. So their API is compatiblewith OpenAI's format. So you can switchyour app from OpenAI to CBRIS in just afew seconds. And since the models areopen and permissibly licensed, you canfine-tune them as well, export them orrun them anywhere else later. So there'sno lock in that you need to worry abouteither. All right, let's get startedwith the demo. This should get you hypedup. We're going to hook up client, whichis an open-source AI coding assistant toCerebras, giving you a coding co-pilotthat is lightning fast and fully underyour control. So, this combination evenbeats things like GitHub copilot or chatGPD in speed while running on openmodels. This setup right here is goingto write 1,000 lines of JavaScript in 4seconds compared to 30 seconds on Gemini2.5 Flash or 80 seconds on Claude 4Sonnet. Getting started is quite simple.Just click on install client. You canfind the links in the description below.Click on VS Code install. Do you want toopen Visual Studio Code allow? It'sgoing to just search for the extensionclient and you can install it. So hereit's installed. You can find it overhere. Here in the settings, selectCerebras. In the API provider, justselect Cerebras. And in the API key,copy your Cerebras API key. Copy thisand paste it over here. Now here you canselect the models. The advanced one isQuen 3 coder 480B. This you can get forfree if you use uh the link that I hadin the description to sign up toCerebrass. And uh just click on done.And there we go. That's essentially it.Also client is agentic. It can read andnavigate your project. It can make aplan and execute changes in varioussteps and you see every move that itmakes. So it's going to be like I amreading these files. I am planning thisapproach. I am writing this function. Itruns on two modes. The plan mode whereit drafts a step-by-step plan that youapprove and the act mode which isbasically where it just goes ahead anddoes the changes under your supervision.So you can select what you want it to doautomatically like the actions. So, it'sgoing to read the projects, edit thefiles, execute the commands, use thebrowser, use MCP servers, and how manyrequests do you want it to do on itsown? Let's say I wanted to do 20requests on its own. So, it's going todo 20 requests on its own. And then it'sgoing to ask you, hey, should Icontinue? So, here I have my remake devswhole website, which is available overhere, and I can basically ask itanything. Umscan through the repositoryand um find securityone abilities and alsomodernize the code.Here you can see how many tokens youknow uh the completion tokens and theprompt tokens and it's going to tell youwhat it's doing. So it wants to readthis file. It's making this API request.It's want it wants to read this file. Itwants to read this file. And uh now it'sgoing to examine some of the keycomponents. Understand the codestructure. It's going to examine thenavbar component, newsletter component,newsletter API. I've identified somecritical security vulnerabilities in thenewsletter API and uh it's going tocheck my whole project and uh as you cansee suggest me answers basically aboutthe question that I asked it. And hereyou can see like the plan. So step onedone, step two done, step three done.Now it's going to implement the codemodernization and then it's going toverify the changes. Pretty cool stuff.And you can see it's pretty fast. After20 API requests are done, I can say yes,you can proceed. Do 20 more. 20 more.You can also increase this limit if youdon't want it to stop after 20 APIrequests. So let's actually ask thissetup to create a clone of this onlinegame. This is a very popular game calledAugur.io. Basically, you have these uhfood items that you eat and you becomebigger. It's a based uh web- basedapplication and uh if something biggercomes, it will eat you and umyou will it will be game over. So, asyou can see, if they eat me, I will begame over. So, in an empty project, Ican give it a prompt like hey create aJavaScript based application for a.ioIO. These are all the repositories youshould have. These are all thestructures you should have. So, as youcan see, it's going to set up theproject structure. You can see the wholetask progresses. So, it's setting up theproject structure and dependencies. It'sgoing to create a backend server usingsocket.io because I told it to. It'sgoing to implement the game logic,create React front-end uh component withTailwind CSS. It's going to implementthe game canvas rendering game UIcomponents. It's going to do everything.It's going to even test the multiplayerfunctionality and then uh implement botplayers and then verify whether it'sready to run or not. It creates thiswhole game. I tested it earlier in like4 minutes and as you can see it's uhwriting the whole code and it's notasking me for approval because I'vegiven it full permission but obviously Iget to check everything and every singlestep that it's doing. I'm not touchingit and it's it's like building thisentire application from scratch. That ispretty cool. After the task iscompleted, as you can see, it created abunch of files for me. It also created areadme file and I just ran npm start.And here is my application that AIcreated. So I can give it a name kunal.And then I can move it around. And youcan see myball will go bigger. I can have a secondplayer. Let's call it Rahul. Start game.And let's say if Rahul collides withKunal, Rahul is gone. Cool stuff. And ithas a score as well. I also asked it tocreate a whole clone of uh Twitter. Soit says write all the code for a fullyworking clone of Twitter. I'm not goingto ask it to stop every 20 after every20 API calls. I need like, I needretweet. I need a backend. I need adatabase. I need APIs for tweets. And uhinfin need infinity scroll on the on thefeed. dark mode to dark dark mode aswell. And I need a bunch of stuff. Ineed a whole working clone of Twitter.And as you can see, it's starting withuh the project structure. It's going toimplement the back end with expressMongoDB socket io create databasemodels, implement user authentication aswell and uh hashtag support and whatnot.So that took like 4 minutes to createand as you can see the tasks are nowcompleted. I can run uh npm install andthen npm install in my client directoryand that should have me giving myTwitter clone. Let's check it out. Sohere I start the backend server. It evencreated readme file for me. This is socool. npm rundev.That's fine.cd client npm starthere I can give it a name kunal kushwahakunalo.comso that's working I can try anothercontact.comalready existsOh, usernameshwahasign up. There we go.As you can see, explore tab,notifications, messages, can search, youcan take a look at your profile, lightmode, dark mode, can I tweet?What's up,Michael Scott?Copy image address,tweet,like, retweet, comment, share. But yeah,that's like the version one, but you canobviously ask it to make it better. Youcan give more detailed prompts and askit to change things little by little.But still, yeah, with just one prompt,pretty cool. I think that's pretty cool.It's working like a real database usingMongoDB. So, yeah, very impressive. Ican ask it to do some other stuff aswell. Let's say this is my Vmake devsrepository. It uses TypeScript and I canask it to let's say I can say you yourtask is to refrator the code to make itmore cleaner, consistent formatting,naming conventions, more modular, typesafe, easier to read and maintain,efficient, do not change the externalbehavior of the code, keep the API same.Show me the full refracted code file byfile. At the end, give me a shortsummary of what improvements have youmade. Let's try the plan version. And Idon't want it to stop after 20iterations. So I'm going to put this as100. Click on next.Soas you can see it's going to work on myinput and um it's agentic. So it's goingto take a look at my project understandit how the files are are structured howthe code is structured. So betterunderstanding the code structure and umthen it's going to give me a plan that Ican execute. So as you can see itfinished um planning that and it says Ihave a good understanding of thecodebase. So it's agentic. So it wentthrough the whole codebase and uh foundthat it's an XJS project and usestailwind components are generally wellstructured could be better. So itcreated this plan that it's going toimprove type safety, enhance componentmodularity, optimize utility functions,improve hooks, organize the datastructures, code formatting,consistency, and whatnot. So it says,would you like me to proceed with thisplan? If so, please toggle to act modeso I can begin implementing theimprovements. So now that I'm happy withthis, I can actually ask it to changesome other stuff. But I'm happy with it.So I'm going to go to act mode andit's going to start working on that. Asyou can see, it's quite fastand it's changing a lot of my filesbased on thestuff I did before. So, you can see sobefore and after. So, we're going to letthat finish. So, here you can see injust a few minutes it has uh completedthe task. So, it's going to give you alittle information like I've refactoredseveral components in the codebase,improved type safety and what's whatnot. It also shows you what files itrefactored and uh these changes make thecodebase a bit more cleaner, moremaintainable. You can see the newchanges as well as you can see here yougo the files that were previous and whatthe change has been. That is quite cool.That is absolutely incredible. So whydoes this combination matter? Well, ifyou're using slower models, client canfeel a little bit laggy when reading lotof files or generating code. But ifyou're using Cerress, code generationcan be 10 to 20 times faster thantypical setups. And with tasks that usedto take like a minute now finish justunder a second as we just saw. It's alsonot just about speed. It's also cheaper.So with Cerebraas claiming 20 times thespeed at, hear me out onetenth the costof closed models in code generationscenarios, which is quite impressive. Soif a better open model drops tomorrow,you can swap it in. And if you want toself-host later, you can do that aswell. So there's no vendor lock in, nodata harvesting unlike copilot and otherclosed source tools. So we havebasically removed the ceiling that heldback small developers or students fromcreating truly powerful AI applications.You can literally build like I don'tknow chat bots. You can build documentanalyzers. You can integrate AI in yourown website. Sky is the limit. And thistech stack is a smart choice because itgives you the best of all the worlds. Soyou get the performance, you get thecost efficiency, you can literally getstarted for free and you also get thefreedom. So you're not sacrificinganything. You're riding the wave of openinnovation rather than being tied to asingle vendor's uh road map. And youknow as AI continues to evolve havingthe flexibility you know that flexiblefoundation it means that you can adaptand adopt new advancements with minimalfriction. I would say we are basicallyseeing the democratization of AIcomputing here. It sort of like remindsme of when cloud computing became athing when I learned about it cuz whenit became a thing I was like a baby. Butyou know suddenly startups you don'tneed to buy their own um you knowservers. you can just rent it out. Andnow with platforms like Cerebras andopen-source AI, you don't actually needto build a giant AI cluster or sign anexpensive uh contract to do cutting edgestuff. Anyone can do it and that's asmart place to be. There was a recent uhboard memo from Google that was leakedas well. I believe it was Sunda Pichaiwho was saying that people are not goingto pay for these proprietary models whenthe free open source models are sort oflike giving them the same sort of likethe same result. But yeah, interestingtimes. I would recommend sign up to theplatform Cerebras using the link in thedescription below and you get uh 200,000tokens as well. build something uh thatyou like and let me know what you builduh by leaving a comment or sharing it onsocials and tagging me. And uh yeah,have fun.[Music]"
  }
]